{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb10631",
   "metadata": {},
   "source": [
    "# LangChain Pinecone OpenAI - Query Your Own Text/PDF File - The Basics\n",
    "\n",
    "#### This notebook walks through the basics of using Pinecone, OpenAI and LangChain to query your own text document \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0fc55",
   "metadata": {},
   "source": [
    "## pip install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccdca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langChain\n",
      "  Using cached langchain-0.1.4-py3-none-any.whl (803 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langChain) (2.31.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langChain) (2.0.3)\n",
      "Collecting langchain-core<0.2,>=0.1.16\n",
      "  Using cached langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.14\n",
      "  Using cached langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
      "Collecting langsmith<0.1,>=0.0.83\n",
      "  Using cached langsmith-0.0.85-py3-none-any.whl (54 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.25-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langChain) (1.22.1)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langChain) (3.7.1)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langChain) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langChain) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langChain) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langChain) (4.7.1)\n",
      "Requirement already satisfied: pydantic-core==2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langChain) (2.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langChain) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langChain) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langChain) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langChain) (2.0.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp39-cp39-win_amd64.whl (290 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: packaging, mypy-extensions, multidict, jsonpointer, frozenlist, yarl, typing-inspect, tenacity, PyYAML, marshmallow, langsmith, jsonpatch, greenlet, async-timeout, aiosignal, SQLAlchemy, langchain-core, dataclasses-json, aiohttp, langchain-community, langChain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.25 aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.3 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langChain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.85 marshmallow-3.20.2 multidict-6.0.4 mypy-extensions-1.0.0 packaging-23.2 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install langChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a6aaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OpenAI\n",
      "  Using cached openai-1.10.0-py3-none-any.whl (225 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from OpenAI) (1.3.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting tqdm>4\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from OpenAI) (4.7.1)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from OpenAI) (3.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from OpenAI) (2.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->OpenAI) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->OpenAI) (1.1.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (2023.7.22)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->OpenAI) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->OpenAI) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>4->OpenAI) (0.4.4)\n",
      "Installing collected packages: h11, httpcore, tqdm, httpx, distro, OpenAI\n",
      "Successfully installed OpenAI-1.10.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "pip install OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pipe\n",
    "\n",
    "\n",
    "Pipe install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c679b5",
   "metadata": {},
   "source": [
    "### Set environment variables and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24cdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEYS, MODELS and ENV Related Settings \n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"\"\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_ENV = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81cc94",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf868f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, langchain, pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64b8ec",
   "metadata": {},
   "source": [
    "### Import your own text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0efff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the data file and read its content\n",
    "\n",
    "file_data = open('./yolo.txt', 'r')\n",
    "file_content = file_data.read()\n",
    "len(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b84d9",
   "metadata": {},
   "source": [
    "### Split the text using RecursiveCharacterTextSplitter to be able to work with the 4096 OpenAI token limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d3f487",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4152/434468475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set up the RecursiveCharacterTextSplitter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m text_splitter = RecursiveCharacterTextSplitter(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Set a really small chunk size, just to show.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up the RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b197f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_splitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4152/727634981.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split the file content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbook_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_splitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_documents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_splitter' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the file content \n",
    "\n",
    "book_texts = text_splitter.create_documents([file_content])\n",
    "print (len(book_texts))\n",
    "type(book_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b0c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='But the Lion went away into the forest and found his own supper, and no\\none ever knew what it was, for he didn’t mention it. And the Scarecrow\\nfound a tree full of nuts and filled Dorothy’s basket with them, so\\nthat she would not be hungry for a long time. She thought this was very\\nkind and thoughtful of the Scarecrow, but she laughed heartily at the\\nawkward way in which the poor creature picked up the nuts. His padded\\nhands were so clumsy and the nuts were so small that he dropped almost\\nas many as he put in the basket. But the Scarecrow did not mind how\\nlong it took him to fill the basket, for it enabled him to keep away\\nfrom the fire, as he feared a spark might get into his straw and burn\\nhim up. So he kept a good distance away from the flames, and only came\\nnear to cover Dorothy with dry leaves when she lay down to sleep. These\\nkept her very snug and warm, and she slept soundly until morning.\\n\\nWhen it was daylight, the girl bathed her face in a little rippling\\nbrook, and soon after they all started toward the Emerald City.\\n\\nThis was to be an eventful day for the travelers. They had hardly been\\nwalking an hour when they saw before them a great ditch that crossed\\nthe road and divided the forest as far as they could see on either\\nside. It was a very wide ditch, and when they crept up to the edge and\\nlooked into it they could see it was also very deep, and there were\\nmany big, jagged rocks at the bottom. The sides were so steep that none\\nof them could climb down, and for a moment it seemed that their journey\\nmust end.\\n\\n“What shall we do?” asked Dorothy despairingly.\\n\\n“I haven’t the faintest idea,” said the Tin Woodman, and the Lion shook\\nhis shaggy mane and looked thoughtful.\\n\\nBut the Scarecrow said, “We cannot fly, that is certain. Neither can we\\nclimb down into this great ditch. Therefore, if we cannot jump over it,\\nwe must stop where we are.”\\n\\n“I think I could jump over it,” said the Cowardly Lion, after measuring\\nthe distance carefully in his mind.' metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(book_texts[31])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced729ba",
   "metadata": {},
   "source": [
    "### Pinecone and OpenAI Embedding setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec5c91b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pinecone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14036/244223036.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Pinecone related setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m pinecone.init(\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPINECONE_API_KEY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0menvironment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPINECONE_ENV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pinecone' is not defined"
     ]
    }
   ],
   "source": [
    "# Pinecone related setup\n",
    "\n",
    "pinecone.init(\n",
    "        api_key = PINECONE_API_KEY,\n",
    "        environment = PINECONE_ENV\n",
    ")\n",
    "\n",
    "# Set the index name for this project in pinecone first\n",
    "\n",
    "index_name = 'testsearchbook'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacf9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40557b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pinecone.list_indexes():\n",
    "    print(\"Index does not exist: \", index_name)\n",
    "\n",
    "\n",
    "book_docsearch = Pinecone.from_texts([t.page_content for t in book_texts], embeddings, index_name = index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58ef6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.vectorstores.pinecone.Pinecone"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book_docsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3601e",
   "metadata": {},
   "source": [
    "### Import  load_qa_chain from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c59e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "121f427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the llm model for our qa session\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4093903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up the query \n",
    "\n",
    "query = \"Who is Dorothy?\"\n",
    "docs = book_docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959007c8",
   "metadata": {},
   "source": [
    "### Ask questions to your document and get the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b4b794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dorothy is a young girl who was carried away by a cyclone from her home. She is innocent and harmless and has never killed anything in her life.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the QA chain with your query to get the answer\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c0a89",
   "metadata": {},
   "source": [
    "## We can also query our own PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d836ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pypdf) (4.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#Import PDF Loader and load the file\n",
    "%pip install pypdf\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./pdfs/yolov7.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121be12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.document_loaders.pdf.PyPDFLoader"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a353d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d2053ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b792ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "766f3fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Scale 28 29 Zeitgeist: 2023 AI Readiness ReportLogistics and Supply Chain\\nLogistics and supply chain com -\\npanies adopt AI to help them \\nimprove operational eﬃciency, \\nimprove customer experience, and \\ngrow revenue.\\nTo help achieve these goals, \\nlogistics and supply chain com -\\npanies are looking to adopt AI for \\nbetter inventory management and \\ndemand forecasting, improved \\nroute optimization, to deploy au -\\ntonomous vehicles, and improve \\ndocument processing throughput \\nand quality. These tools directly \\nimpact operational eﬃciency, \\nwhich has downstream impacts on \\nthe overall customer experience, \\nwith reliable delivery and fewer \\ndelays.\\nFor inventory management and \\ndemand forecasting, logistics \\nand supply chain companies are \\nadopting AI to help reduce costs, \\nimprove customer satisfaction, \\nand improve forecast accuracy.TOP USE CASES BY INDUSTRYLogistics and Supply Chain\\nFor route planning, logistics and \\nsupply chain companies believe AI \\ncan help improve eﬃciency, reduce \\ncosts, improve delivery accuracy, \\nand reduce shipping times. This \\ndirectly translates to improved \\noperational eﬃciency and a better \\ncustomer experience while indirect -\\nly translating to revenue growth.\\nFor document processing, logistics \\nand supply chain companies look \\nto AI to help them with informa -\\ntion processing, document clas -\\nsiﬁcation, and compliance. This \\napplication is strictly dedicated to \\nincreasing operational eﬃciency \\nand reducing costs.\\nLogistics and supply chain com -\\npanies process a lot of paperwork. \\nTo improve operational eﬃciency, \\nthis paperwork must be pro -\\ncessed as quickly and accurately \\nas possible. Logistics documents, \\nsuch as bills of lading, commercial \\ninvoices, and packing lists are full \\nof critical information required to \\nclear shipments past customs and \\nonto warehouses for distribution. \\nTraditional OCR applications re -\\nquire the creation of templates for \\neach type of document, which is \\ninfeasible and ineﬃcient for global \\nlogistics companies. Instead, these \\ncompanies rely on machine-learn -\\ning-powered document process -\\ning, which requires no templates \\nand still processes the documents \\nat over over 95% accuracy.TOP USE CASES BY INDUSTRY', metadata={'source': '../data/Scale-Zeitgeist-AI-Readiness-Report-2023.pdf', 'page': 15})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c95f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_texts = text_splitter.split_documents(file_content)\n",
    "print (len(book_texts))\n",
    "type(book_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3090e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Enterprises are mostly looking to leverage open-source generative models (41%) or Cloud API generative models (37%), while very few are looking to build their own generative models (22%). Furthermore, 28% are exclusively using open-source models, while 26% use cloud APIs and only 15% are exclusively building their own.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's set up the query \n",
    "\n",
    "query = \"How are enterprises working with generative ai?\"\n",
    "docs = book_docsearch.similarity_search(query)\n",
    "\n",
    "# Run the QA chain with your query to get the answer\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dcfc0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Companies adopting AI are seeing positive outcomes from improved customer experiences, the ability to develop new products or services and improve existing products, and improved collaboration across business functions.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's set up a different query \n",
    "\n",
    "query = \"What outcomes have companies seen from AI adoption?\"\n",
    "docs = book_docsearch.similarity_search(query)\n",
    "\n",
    "# Run the QA chain with your query to get the answer\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4cff3abf1678755e0069fd79299a535fe1940bcd71a6b01d9f4386710b2b163f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
